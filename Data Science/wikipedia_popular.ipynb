{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "from pyspark.sql import SparkSession, functions, types\n",
    "import ntpath\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate \n",
    "spark = SparkSession.builder.appName('reddit averages').getOrCreate()\n",
    "spark.sparkContext.setLogLevel('WARN')\n",
    "\n",
    "assert sys.version_info >= (3, 5) # make sure we have Python 3.5+\n",
    "assert spark.version >= '2.3' # make sure we have Spark 2.3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema\n",
    "pages_schema = types.StructType([\n",
    "    types.StructField('page', types.StringType()),\n",
    "    types.StructField('title', types.StringType()),\n",
    "    types.StructField('requests', types.IntegerType()),\n",
    "    types.StructField('bytes', types.IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------+-------+--------------------+\n",
      "|page|               title|requests|  bytes|            filename|\n",
      "+----+--------------------+--------+-------+--------------------+\n",
      "|  en|Simon_%22Ghost%22...|       2|  39816|file:///Users/cha...|\n",
      "|  en| Simon_%26_Garfunkel|      91|4543932|file:///Users/cha...|\n",
      "|  en|Simon_%26_Garfunk...|      19| 748974|file:///Users/cha...|\n",
      "|  en|  Simon_%26_Schuster|      18| 883010|file:///Users/cha...|\n",
      "|  en|Simon_%26_Schuste...|       1|   6651|file:///Users/cha...|\n",
      "|  en|Simon_%26_Schuste...|       1|  28288|file:///Users/cha...|\n",
      "|  en|Simon_%26_Schuste...|       1|  28333|file:///Users/cha...|\n",
      "|  en|Simon_%26_Schuste...|       1|  28338|file:///Users/cha...|\n",
      "|  en|Simon_%26_Schuste...|       1|  28316|file:///Users/cha...|\n",
      "|  en|Simon_%26_Schuste...|       1|  28317|file:///Users/cha...|\n",
      "|  en|     Simon_%26_Simon|      11| 268170|file:///Users/cha...|\n",
      "|  en|    Simon_%28game%29|       1|  22180|file:///Users/cha...|\n",
      "|  en|   Simon_%C5%A0pilak|       1|  13958|file:///Users/cha...|\n",
      "|  en|   Simon_(1980_film)|       1|  10414|file:///Users/cha...|\n",
      "|  en|Simon_(Battlestar...|       1|  39731|file:///Users/cha...|\n",
      "|  en|Simon_(Gurren_Lag...|       1|  36043|file:///Users/cha...|\n",
      "|  en|Simon_(brother_of...|       1|  14932|file:///Users/cha...|\n",
      "|  en|         Simon_(cat)|       1|  14103|file:///Users/cha...|\n",
      "|  en|      Simon_(cipher)|       1|  13668|file:///Users/cha...|\n",
      "|  en|    Simon_(computer)|       1|   9949|file:///Users/cha...|\n",
      "+----+--------------------+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('pagecounts-1/', sep=' ', schema=pages_schema).\\\n",
    "    withColumn('filename', functions.input_file_name()).cache()\n",
    "df = df.filter((df.page == 'en') & (df.title != 'Main_Page') & \\\n",
    "              ~df.title.startswith('Special:'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(path):\n",
    "    base = ntpath.basename(path)\n",
    "    try:\n",
    "        res = re.search('-(.+?-\\d{1,2})[0]', base).group(1)\n",
    "    except AttributeError:\n",
    "        res = ''\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_hour = functions.udf(get_date, returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('hour', path_to_hour('filename'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxHours = df.groupBy('hour').max('requests').withColumnRenamed('max(requests)', 'max')\n",
    "MaxHours = MaxHours.withColumnRenamed('hour', 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(MaxHours, (df.hour == MaxHours.h) & (df.requests == MaxHours.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       hour|\n",
      "+-----------+\n",
      "|20160801-00|\n",
      "|20160801-01|\n",
      "|20160801-02|\n",
      "|20160801-03|\n",
      "|20160801-04|\n",
      "|20160801-05|\n",
      "|20160801-06|\n",
      "|20160801-07|\n",
      "|20160801-08|\n",
      "|20160801-09|\n",
      "|20160801-10|\n",
      "|20160801-11|\n",
      "|20160801-12|\n",
      "|20160801-13|\n",
      "|20160801-14|\n",
      "|20160801-15|\n",
      "|20160801-16|\n",
      "|20160801-17|\n",
      "|20160801-18|\n",
      "|20160801-19|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('h', 'max').sort('hour', 'title')\n",
    "df = df.select('hour', 'title', 'requests')\n",
    "df.select('hour').distinct().sort('hour').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(9) HashAggregate(keys=[hour#85], functions=[count(requests#2)])\n",
      "+- Exchange hashpartitioning(hour#85, 200)\n",
      "   +- *(8) HashAggregate(keys=[hour#85], functions=[partial_count(requests#2)])\n",
      "      +- *(8) Project [hour#85, requests#2]\n",
      "         +- *(8) Sort [hour#85 ASC NULLS FIRST, title#1 ASC NULLS FIRST], true, 0\n",
      "            +- Exchange rangepartitioning(hour#85 ASC NULLS FIRST, title#1 ASC NULLS FIRST, 200)\n",
      "               +- *(7) Project [title#1, requests#2, hour#85]\n",
      "                  +- *(7) BroadcastHashJoin [hour#85, requests#2], [h#105, max#102], Inner, BuildRight\n",
      "                     :- *(7) Project [title#1, requests#2, pythonUDF0#795 AS hour#85]\n",
      "                     :  +- BatchEvalPython [get_date(filename#8)], [filename#8, requests#2, title#1, pythonUDF0#795]\n",
      "                     :     +- *(2) Project [filename#8, requests#2, title#1]\n",
      "                     :        +- *(2) Project [page#0, title#1, requests#2, bytes#3, filename#8]\n",
      "                     :           +- *(2) Filter isnotnull(pythonUDF0#794)\n",
      "                     :              +- BatchEvalPython [get_date(filename#8)], [page#0, title#1, requests#2, bytes#3, filename#8, pythonUDF0#794]\n",
      "                     :                 +- *(1) Filter (((((isnotnull(page#0) && isnotnull(title#1)) && (page#0 = en)) && NOT (title#1 = Main_Page)) && NOT StartsWith(title#1, Special:)) && isnotnull(requests#2))\n",
      "                     :                    +- InMemoryTableScan [page#0, title#1, requests#2, bytes#3, filename#8], [isnotnull(page#0), isnotnull(title#1), (page#0 = en), NOT (title#1 = Main_Page), NOT StartsWith(title#1, Special:), isnotnull(requests#2)]\n",
      "                     :                          +- InMemoryRelation [page#0, title#1, requests#2, bytes#3, filename#8], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                     :                                +- *(1) Project [page#0, title#1, requests#2, bytes#3, input_file_name() AS filename#8]\n",
      "                     :                                   +- *(1) FileScan csv [page#0,title#1,requests#2,bytes#3] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/chadmalla/Desktop/cmpt353/e10/pagecounts-1], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<page:string,title:string,requests:int,bytes:int>\n",
      "                     +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true], input[1, int, false]))\n",
      "                        +- *(6) Filter isnotnull(max#102)\n",
      "                           +- *(6) HashAggregate(keys=[hour#85], functions=[max(requests#2)])\n",
      "                              +- Exchange hashpartitioning(hour#85, 200)\n",
      "                                 +- *(5) HashAggregate(keys=[hour#85], functions=[partial_max(requests#2)])\n",
      "                                    +- *(5) Project [requests#2, pythonUDF0#797 AS hour#85]\n",
      "                                       +- BatchEvalPython [get_date(filename#8)], [filename#8, requests#2, pythonUDF0#797]\n",
      "                                          +- *(4) Project [filename#8, requests#2]\n",
      "                                             +- *(4) Project [page#0, title#1, requests#2, bytes#3, filename#8]\n",
      "                                                +- *(4) Filter isnotnull(pythonUDF0#796)\n",
      "                                                   +- BatchEvalPython [get_date(filename#8)], [page#0, title#1, requests#2, bytes#3, filename#8, pythonUDF0#796]\n",
      "                                                      +- *(3) Filter ((((isnotnull(page#0) && isnotnull(title#1)) && (page#0 = en)) && NOT (title#1 = Main_Page)) && NOT StartsWith(title#1, Special:))\n",
      "                                                         +- InMemoryTableScan [page#0, title#1, requests#2, bytes#3, filename#8], [isnotnull(page#0), isnotnull(title#1), (page#0 = en), NOT (title#1 = Main_Page), NOT StartsWith(title#1, Special:)]\n",
      "                                                               +- InMemoryRelation [page#0, title#1, requests#2, bytes#3, filename#8], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                                                                     +- *(1) Project [page#0, title#1, requests#2, bytes#3, input_file_name() AS filename#8]\n",
      "                                                                        +- *(1) FileScan csv [page#0,title#1,requests#2,bytes#3] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/chadmalla/Desktop/cmpt353/e10/pagecounts-1], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<page:string,title:string,requests:int,bytes:int>\n"
     ]
    }
   ],
   "source": [
    "df1 = df.select('hour', 'requests')\n",
    "df1 = df.groupby('hour').agg({'requests': 'count'})\n",
    "df1.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
