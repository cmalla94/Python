{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession, functions, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate code\n",
    "spark = SparkSession.builder.appName('weather ETL').getOrCreate()\n",
    "spark.sparkContext.setLogLevel('WARN')\n",
    "\n",
    "assert sys.version_info >= (3, 5) # make sure we have Python 3.5+\n",
    "assert spark.version >= '2.3' # make sure we have Spark 2.3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the schema for when the data is imported\n",
    "observation_schema = types.StructType([\n",
    "    types.StructField('station', types.StringType()),\n",
    "    types.StructField('date', types.StringType()),\n",
    "    types.StructField('observation', types.StringType()),\n",
    "    types.StructField('value', types.IntegerType()),\n",
    "    types.StructField('mflag', types.StringType()),\n",
    "    types.StructField('qflag', types.StringType()),\n",
    "    types.StructField('sflag', types.StringType()),\n",
    "    types.StructField('obstime', types.StringType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function \n",
    "def main():\n",
    "    in_directory = 'weather-1/'\n",
    "    out_directory = 'output/'\n",
    "\n",
    "    weather = spark.read.csv(in_directory, schema=observation_schema)\n",
    "\n",
    "    # TODO: finish here.\n",
    "    # DONE\n",
    "    cleaned_data = weather.filter(weather.qflag.isNull())\\\n",
    "        .filter(weather.station.startswith('CA'))\\\n",
    "        .filter(weather.observation.startswith('TMAX'))\\\n",
    "        .select(weather['station'], weather['date'], (weather.value/10).alias('tmax'))\n",
    "    cleaned_data.show()\n",
    "\n",
    "    cleaned_data.write.json(out_directory, compression='gzip', mode='overwrite')\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+\n",
      "|    station|    date|tmax|\n",
      "+-----------+--------+----+\n",
      "|CA001157630|20161203| 4.5|\n",
      "|CA004015322|20161203| 2.1|\n",
      "|CA003010162|20161203| 2.5|\n",
      "|CA001085836|20161203| 2.2|\n",
      "|CA006135583|20161203| 5.0|\n",
      "|CA007093714|20161203|-9.1|\n",
      "|CA007018563|20161203| 1.6|\n",
      "|CA001184791|20161203| 2.4|\n",
      "|CA002400573|20161203|-7.2|\n",
      "|CA006016529|20161203|-5.7|\n",
      "|CA00615EMR7|20161203| 4.0|\n",
      "|CA001101158|20161203| 6.5|\n",
      "|CA002402353|20161203|-7.6|\n",
      "|CA001077499|20161203| 3.7|\n",
      "|CA004010879|20161203|-1.2|\n",
      "|CA008403690|20161203| 1.5|\n",
      "|CA004016322|20161203|-0.5|\n",
      "|CA001173210|20161203| 1.0|\n",
      "|CA007061288|20161203|-4.2|\n",
      "|CA003032550|20161203| 8.4|\n",
      "+-----------+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+\n",
      "|    station|    date|tmax|\n",
      "+-----------+--------+----+\n",
      "|CA001157630|20161203| 4.5|\n",
      "|CA004015322|20161203| 2.1|\n",
      "|CA003010162|20161203| 2.5|\n",
      "|CA001085836|20161203| 2.2|\n",
      "|CA006135583|20161203| 5.0|\n",
      "|CA007093714|20161203|-9.1|\n",
      "|CA007018563|20161203| 1.6|\n",
      "|CA001184791|20161203| 2.4|\n",
      "|CA002400573|20161203|-7.2|\n",
      "|CA006016529|20161203|-5.7|\n",
      "|CA00615EMR7|20161203| 4.0|\n",
      "|CA001101158|20161203| 6.5|\n",
      "|CA002402353|20161203|-7.6|\n",
      "|CA001077499|20161203| 3.7|\n",
      "|CA004010879|20161203|-1.2|\n",
      "|CA008403690|20161203| 1.5|\n",
      "|CA004016322|20161203|-0.5|\n",
      "|CA001173210|20161203| 1.0|\n",
      "|CA007061288|20161203|-4.2|\n",
      "|CA003032550|20161203| 8.4|\n",
      "+-----------+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cache()\n",
    "result = data.groupBy('date').count().sort('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|    date|count(tmax)|\n",
      "+--------+-----------+\n",
      "|20161203|         84|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('date').agg({'tmax': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
